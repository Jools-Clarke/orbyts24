{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "# use GPU if available for faster training times\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Using GPU')\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print('Using MPS')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Using CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdown https://drive.google.com/uc?id=1LK65H6dtv34R_evtIHZGFPJlvCDFdWA7 -O data.hdf5\n",
    "! gdown https://drive.google.com/uc?id=1p0QrCMYTlWaHjo-XxZvp1d704RlENhgU -O trained_model_weights.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('data.hdf5')\n",
    "\n",
    "spectra = ds['spectra'].values\n",
    "print(spectra.shape)\n",
    "\n",
    "# Use numpy.isnan to check for NaN values\n",
    "nan_count = np.isnan(spectra).sum()\n",
    "print(f\"Number of NaN values: {nan_count}\")\n",
    "\n",
    "# Remove NaN values by replacing them with 0\n",
    "spectra = np.nan_to_num(spectra)\n",
    "print(spectra.shape)\n",
    "\n",
    "\n",
    "def min_max_normaliser(x, dim=None):\n",
    "    '''normalises the input np array to the range [0, 1]'''\n",
    "\n",
    "    x = np.array(x)\n",
    "    x_min = np.min(x, axis=dim, keepdims=True)\n",
    "    x_max = np.max(x, axis=dim, keepdims=True)\n",
    "\n",
    "    x = (x-x_min)/(x_max-x_min + np.finfo(float).eps)\n",
    "\n",
    "    return x\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectra Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3), dpi=500)\n",
    "plt.plot(ds['wavelength'], spectra[0]*100, color='black') # Plot the first spectrum, the 0 here means the first, so we can change that to 1 to plot the second, or 2 for the 3rd etc\n",
    "plt.xscale('log')\n",
    "plt.xticks([1, 2, 3, 5, 7], ['1µm', '2µm', '3µm', '5µm', '7µm'])\n",
    "plt.xlabel('Wavelength (µm)')\n",
    "plt.ylabel('Tranit Depth (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Spectra Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3), dpi=500)\n",
    "for i in range(1, 35): # Loop through the first 35 spectra\n",
    "    plt.plot(ds['wavelength'], spectra[i]*100, alpha=0.5) # Plot the spectra with a different colour, and a little transparency, this is what alpha=0.5 does. alpha=1 is fully opaque, and alpha=0 is fully transparent\n",
    "plt.xscale('log')\n",
    "plt.xticks([1, 2, 3, 5, 7], ['1µm', '2µm', '3µm', '5µm', '7µm'])\n",
    "plt.xlabel('Wavelength (µm)')\n",
    "plt.ylabel('Tranit Depth (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the model, and create the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_molecules = ['H2O', 'CH4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_header = ds['molecules'].values\n",
    "chemical_abundances = ds['log_abundance'].values\n",
    "\n",
    "print(mol_header)\n",
    "print(chemical_abundances.shape)\n",
    "\n",
    "\n",
    "index = np.isin(mol_header, included_molecules)\n",
    "\n",
    "labels = chemical_abundances[:, index]\n",
    "labels.shape\n",
    "\n",
    "# split train into train and test - we will use the test data to evaluate the model\n",
    "\n",
    "tts = [0.8, 0.2] # 80% train, 20% test\n",
    "seed = 42 # random seed for reproducibility\n",
    "train_spectra, test_spectra, train_labels, test_labels = train_test_split(\n",
    "    min_max_normaliser(spectra, dim=1), # here we input the regular spectra, but we should probably use the normalised spectra\n",
    "    labels,\n",
    "    test_size=tts[1],\n",
    "    random_state=seed)\n",
    "\n",
    "# print shapes in table\n",
    "print(f\"\"\"\n",
    "train_spectra: {train_spectra.shape}\n",
    "train_labels: {train_labels.shape}\n",
    "\n",
    "test_spectra: {test_spectra.shape}\n",
    "test_labels: {test_labels.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedDeeperModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedDeeperModel, self).__init__()\n",
    "        self.shortcut_proj = nn.Linear(1024, 512)\n",
    "\n",
    "        self.fc1 = nn.Linear(52, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(0.05)\n",
    "\n",
    "        self.fc2 = nn.Linear(1024, 768)\n",
    "        self.bn2 = nn.BatchNorm1d(768)\n",
    "        self.dropout2 = nn.Dropout(0.05)\n",
    "\n",
    "        self.fc3 = nn.Linear(768, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.dropout3 = nn.Dropout(0.1)  # <- middle dropout a bit higher\n",
    "\n",
    "        self.fc4 = nn.Linear(512, 384)\n",
    "        self.bn4 = nn.BatchNorm1d(384)\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "\n",
    "        self.fc5 = nn.Linear(384, 256)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.dropout5 = nn.Dropout(0.1)\n",
    "\n",
    "        self.fc6 = nn.Linear(256, 128)\n",
    "        self.bn6 = nn.BatchNorm1d(128)\n",
    "        self.dropout6 = nn.Dropout(0.05)  # -> slightly lower again\n",
    "\n",
    "        self.fc7 = nn.Linear(128, 64)\n",
    "        self.bn7 = nn.BatchNorm1d(64)\n",
    "        self.dropout7 = nn.Dropout(0.05)\n",
    "\n",
    "        self.fc8 = nn.Linear(64, 32)\n",
    "        self.bn8 = nn.BatchNorm1d(32)\n",
    "        self.dropout8 = nn.Dropout(0.05)\n",
    "\n",
    "        self.fc9 = nn.Linear(32, 2) #1) #CHANGED THIS 1 TO A 2 as you are predicting on TWO species \n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass with optional tiny residual skip after first 3 layers\n",
    "        x1 = F.silu(self.bn1(self.fc1(x)))\n",
    "        x1 = self.dropout1(x1)\n",
    "\n",
    "        x2 = F.silu(self.bn2(self.fc2(x1)))\n",
    "        x2 = self.dropout2(x2)\n",
    "\n",
    "        x3 = F.silu(self.bn3(self.fc3(x2)))\n",
    "        x3 = self.dropout3(x3)\n",
    "\n",
    "        shortcut = self.shortcut_proj(x1)  # project x1\n",
    "        x3 = x3 + shortcut * 0.1\n",
    "\n",
    "\n",
    "        x4 = F.silu(self.bn4(self.fc4(x3)))\n",
    "        x4 = self.dropout4(x4)\n",
    "\n",
    "        x5 = F.silu(self.bn5(self.fc5(x4)))\n",
    "        x5 = self.dropout5(x5)\n",
    "\n",
    "        x6 = F.silu(self.bn6(self.fc6(x5)))\n",
    "        x6 = self.dropout6(x6)\n",
    "\n",
    "        x7 = F.silu(self.bn7(self.fc7(x6)))\n",
    "        x7 = self.dropout7(x7)\n",
    "\n",
    "        x8 = F.silu(self.bn8(self.fc8(x7)))\n",
    "        x8 = self.dropout8(x8)\n",
    "\n",
    "        out = self.fc9(x8)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for layer in [\n",
    "            self.fc1, self.fc2, self.fc3, self.fc4,\n",
    "            self.fc5, self.fc6, self.fc7, self.fc8, self.fc9\n",
    "        ]:\n",
    "            init.kaiming_normal_(layer.weight, nonlinearity='relu', mode='fan_out')\n",
    "            init.constant_(layer.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImprovedDeeperModel().to(device)\n",
    "model.to(device)\n",
    "\n",
    "## load model weights from disk\n",
    "model_path = 'trained_model_weights.pth'\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spectra = torch.Tensor(test_spectra).to(device)\n",
    "test_labels = torch.Tensor(test_labels).to(device)\n",
    "\n",
    "# TEST FORWARD PASS TO DEBUG NAN ISSUE\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_spectra)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0 # for H2O\n",
    "i = 1 # for CH4\n",
    "plt.figure(figsize=(5, 5), dpi=500)\n",
    "plt.plot(test_labels.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i],'kx', label=mol_header[i], alpha=0.5)\n",
    "\n",
    "plt.plot([test_labels.cpu().numpy()[:, i].min(),\n",
    "        test_labels.cpu().numpy()[:, i].max()],\n",
    "        [test_labels.cpu().numpy()[:, i].min(),\n",
    "        test_labels.cpu().numpy()[:, i].max()], 'r--', lw=2)\n",
    "\n",
    "plt.xlabel(f'True Abundance of {mol_header[index][i]}')\n",
    "plt.ylabel(f'Predicted Abundance of {mol_header[index][i]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binned Performance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "true_values = test_labels.cpu().numpy()[:, i]\n",
    "predicted_values = test_outputs.cpu().numpy()[:, i]\n",
    "\n",
    "# Step 1: Bin data along the x-axis\n",
    "num_bins = 10\n",
    "bins = np.linspace(true_values.min(), true_values.max(), num_bins + 1)\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "# Initialize arrays to store metrics\n",
    "bin_means, bin_stds, bin_mins, bin_maxs = [], [], [], []\n",
    "bin_lower_95, bin_upper_95 = [], []\n",
    "\n",
    "# Step 2: Compute metrics for each bin\n",
    "for j in range(num_bins):\n",
    "    bin_mask = (true_values >= bins[j]) & (true_values < bins[j + 1])\n",
    "    bin_data = predicted_values[bin_mask]\n",
    "    \n",
    "    if bin_data.size > 0:\n",
    "        bin_means.append(bin_data.mean())\n",
    "        bin_stds.append(bin_data.std())\n",
    "        bin_mins.append(bin_data.min())\n",
    "        bin_maxs.append(bin_data.max())\n",
    "        bin_lower_95.append(np.percentile(bin_data, 2.5))\n",
    "        bin_upper_95.append(np.percentile(bin_data, 97.5))\n",
    "    else:\n",
    "        bin_means.append(np.nan)\n",
    "        bin_stds.append(np.nan)\n",
    "        bin_mins.append(np.nan)\n",
    "        bin_maxs.append(np.nan)\n",
    "        bin_lower_95.append(np.nan)\n",
    "        bin_upper_95.append(np.nan)\n",
    "\n",
    "# Step 3: Plot results\n",
    "plt.figure(figsize=(5, 5), dpi=500)\n",
    "\n",
    "# Mean with standard deviation as error bars\n",
    "plt.errorbar(bin_centers, bin_means, yerr=bin_stds, fmt='x', label='Mean ± Std', capsize=4, color='black')\n",
    "\n",
    "# Min and Max with 'v' and '^' markers\n",
    "plt.plot(bin_centers, bin_mins, '^', label='Min/Max', alpha=0.7, color='red')\n",
    "plt.plot(bin_centers, bin_maxs, 'v', alpha=0.7, color='red')\n",
    "\n",
    "# 95% confidence interval with different colors\n",
    "plt.plot(bin_centers, bin_lower_95, '^', label='95% CI', alpha=0.7, color='orange')\n",
    "plt.plot(bin_centers, bin_upper_95, 'v',  alpha=0.7, color='orange')\n",
    "\n",
    "# 1:1 reference line\n",
    "plt.plot([true_values.min(), true_values.max()],\n",
    "         [true_values.min(), true_values.max()], '--', lw=2, label='1:1 Line', color='red')\n",
    "\n",
    "# Labels, legend, and show\n",
    "plt.xlabel(f'True Abundance of {mol_header[index][i]} (log)')\n",
    "plt.ylabel(f'Predicted Abundance of {mol_header[index][i]} (log)')\n",
    "plt.legend(loc='upper left', fontsize='small', frameon=False)\n",
    "\n",
    "plt.xlim(true_values.min(), true_values.max())\n",
    "plt.ylim(true_values.min(), true_values.max())\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ariel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
